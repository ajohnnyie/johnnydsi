{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import scipy\n",
    "import requests\n",
    "from imdbpie import Imdb\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import collections\n",
    "import re\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imdbpie\n",
      "  Downloading imdbpie-4.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): six<2.0.0,>=1.0.0 in /anaconda/lib/python2.7/site-packages (from imdbpie)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests>=0.10 in /anaconda/lib/python2.7/site-packages (from imdbpie)\n",
      "Collecting cachecontrol[filecache] (from imdbpie)\n",
      "  Downloading CacheControl-0.11.6.tar.gz\n",
      "Requirement already satisfied (use --upgrade to upgrade): wheel in /anaconda/lib/python2.7/site-packages (from imdbpie)\n",
      "Collecting lockfile>=0.9 (from cachecontrol[filecache]->imdbpie)\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: cachecontrol\n",
      "  Running setup.py bdist_wheel for cachecontrol ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/johnnywang/Library/Caches/pip/wheels/e3/7e/92/702a2e4402e680204b83d837aa67dc7ca80e93abfdf62d3ac6\n",
      "Successfully built cachecontrol\n",
      "Installing collected packages: lockfile, cachecontrol, imdbpie\n",
      "Successfully installed cachecontrol-0.11.6 imdbpie-4.0.2 lockfile-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install imdbpie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Work: Write a problem statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Acquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the IMDB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb = Imdb()\n",
    "imdb = Imdb(anonymize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Query the top 250 rated movies in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies250=pd.DataFrame(imdb.top_250())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Only select the top 25 movies and delete the uncessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies25=movies250.ix[:25]\n",
    "del movies25[\"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Write the Results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies25.to_csv('movies25.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Wrangle the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Convert the listing identification numbers (tconst) from the first dataframe to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"movies25.csv\")\n",
    "tconstList = movies[\"tconst\"].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Scrape the reviews for the top 25 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: Use a loop to scrape each page at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reviews=[]\n",
    "#for i in range(25):\n",
    "#    reviews.append(imdb.get_title_reviews(tconstList[i], max_results=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#review = pd.concat([movies[\"tconst\"], pd.DataFrame(reviews)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviewtext = []\n",
    "Id = []\n",
    "for x in movies['tconst']:\n",
    "    reviews = imdb.get_title_reviews(x, max_results=15)\n",
    "    for review in reviews:\n",
    "        Id.append(x)\n",
    "        reviewtext.append(review.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Work through each title and find the most common descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: \"soup\" from BeautifulSoup is the html returned from all 25 pages. You'll need to either address each page individually or break them down by elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'great',\n",
       " u'first',\n",
       " u'many',\n",
       " u'other',\n",
       " u'good',\n",
       " u'much',\n",
       " u'same',\n",
       " u'such',\n",
       " u'own',\n",
       " u'real',\n",
       " u'second',\n",
       " u'true',\n",
       " u'little',\n",
       " u'different',\n",
       " u'original',\n",
       " u'few',\n",
       " u'new',\n",
       " u'excellent',\n",
       " u'last',\n",
       " u'perfect',\n",
       " u'special',\n",
       " u'long',\n",
       " u'whole',\n",
       " u'young',\n",
       " u'human',\n",
       " u'old',\n",
       " u'brilliant',\n",
       " u'big',\n",
       " u\"'t\",\n",
       " u'entire',\n",
       " u'powerful',\n",
       " u'bad',\n",
       " u'final',\n",
       " u'amazing',\n",
       " u'main',\n",
       " u'classic',\n",
       " u'beautiful',\n",
       " u'favorite',\n",
       " u'dark',\n",
       " u'memorable',\n",
       " u'important',\n",
       " u'simple',\n",
       " u'high',\n",
       " u'right',\n",
       " u'visual',\n",
       " u'strong',\n",
       " u'wonderful',\n",
       " u'top',\n",
       " u'emotional',\n",
       " u'single']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use this to isolate each word in the review\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "tokens = [tokenizer.tokenize(i) for i in reviewtext]\n",
    "tag = [nltk.pos_tag(i) for i in tokens]\n",
    "tag\n",
    "\n",
    "#use this to select the words that are adjective\n",
    "adjectives = []\n",
    "for x in (tag):\n",
    "    for a,b in x:\n",
    "        if b == \"JJ\":\n",
    "            adjectives.append(a)\n",
    "        \n",
    "\n",
    "#use this to select the most common\n",
    "c = collections.Counter\n",
    "count = c(adjectives)\n",
    "mostCommon = [a for a,b in count.most_common(50)]\n",
    "mostCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfCommon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Convert to a string and remove the non AlphaNumeric characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: Use regular expressions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Tokenize the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Convert to a Dataframe for Easy Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  7. Find the rows with the top five descriptive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ('best', 'hope', 'love', 'beautiful', 'great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Write the results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Repeat the process for the other top 24 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combine Tables in PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import your two .csv data files into your Postgre Database as two different tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease, we can call these table1 and table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Connect to database and query the joined set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Join the two tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Select the newly joined table and save two copies of the into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Parsing and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Rename the column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run a description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. What is our target attribute? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare the data and define the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Set up test data and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. What is overfitting and how are we at risk? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
